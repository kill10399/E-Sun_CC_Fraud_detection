{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data, N(number of observation), N_f(number of features)\n",
    "from _data import train_raw, N, N_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try PCA\n",
    "\n",
    "## some ideas:\n",
    "- create new cols store information by acct\n",
    "- clustering the acct by avg_txn_amt, avg_month_amt, types of spending type, acc_code.....\n",
    "\n",
    "#### even more ideas: \n",
    "- fit a dist model of txn time, txn number for every group --> give every txn a probability.\n",
    "- try use one-class SVM (for novelty detection) see <a href=\"http://papers.nips.cc/paper/1723-support-vector-method-for-novelty-detection.pdf\" > paper </a> for explain and exmple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### comput attribute by acct "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute unique value for each featue\n",
    "def count_unique(df):\n",
    "    unique_dict = {}\n",
    "    for i in df.columns:\n",
    "        uni_val = df[i].unique()\n",
    "        unique_dict[i]=(len(uni_val), uni_val)\n",
    "    return unique_dict\n",
    "unique_dict = count_unique(train_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "bool_col=[]\n",
    "for i in unique_dict:\n",
    "    if unique_dict[i][0]<=3:\n",
    "        bool_col.append(i)\n",
    "\n",
    "bool_col.remove('fraud_ind')\n",
    "bool_agg = {i:'sum' for i in bool_col}\n",
    "\n",
    "col_nm_txn = ['tx_amt_avg', 'tx_cnt']\n",
    "by_txn = train_raw.groupby('bacno').agg({'conam':['mean','count'], **bool_agg})\n",
    "by_txn.columns=col_nm_txn+[i+'_count' for i in bool_col]\n",
    "by_txn.replace(np.NAN, 0,inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tx_amt_avg</th>\n",
       "      <th>tx_cnt</th>\n",
       "      <th>ecfg_count</th>\n",
       "      <th>flbmk_count</th>\n",
       "      <th>flg_3dsmk_count</th>\n",
       "      <th>insfg_count</th>\n",
       "      <th>ovrlt_count</th>\n",
       "      <th>stscd_0</th>\n",
       "      <th>stscd_1</th>\n",
       "      <th>stscd_2</th>\n",
       "      <th>stscd_3</th>\n",
       "      <th>stscd_4</th>\n",
       "      <th>stscd_0</th>\n",
       "      <th>stscd_1</th>\n",
       "      <th>stscd_2</th>\n",
       "      <th>stscd_3</th>\n",
       "      <th>stscd_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>95214.000000</td>\n",
       "      <td>95214.000000</td>\n",
       "      <td>95214.000000</td>\n",
       "      <td>95214.000000</td>\n",
       "      <td>95214.000000</td>\n",
       "      <td>95214.000000</td>\n",
       "      <td>95214.000000</td>\n",
       "      <td>95214.000000</td>\n",
       "      <td>95214.000000</td>\n",
       "      <td>95214.000000</td>\n",
       "      <td>95214.000000</td>\n",
       "      <td>95214.000000</td>\n",
       "      <td>95214.000000</td>\n",
       "      <td>95214.000000</td>\n",
       "      <td>95214.000000</td>\n",
       "      <td>95214.000000</td>\n",
       "      <td>95214.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>732.571089</td>\n",
       "      <td>15.982807</td>\n",
       "      <td>4.067417</td>\n",
       "      <td>0.053280</td>\n",
       "      <td>0.675730</td>\n",
       "      <td>0.444388</td>\n",
       "      <td>0.212689</td>\n",
       "      <td>15.782816</td>\n",
       "      <td>0.004285</td>\n",
       "      <td>0.194362</td>\n",
       "      <td>0.001134</td>\n",
       "      <td>0.000210</td>\n",
       "      <td>15.782816</td>\n",
       "      <td>0.004285</td>\n",
       "      <td>0.194362</td>\n",
       "      <td>0.001134</td>\n",
       "      <td>0.000210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>338.143649</td>\n",
       "      <td>21.017744</td>\n",
       "      <td>10.538025</td>\n",
       "      <td>0.336961</td>\n",
       "      <td>2.417233</td>\n",
       "      <td>2.196183</td>\n",
       "      <td>2.001265</td>\n",
       "      <td>20.658418</td>\n",
       "      <td>0.194617</td>\n",
       "      <td>1.786932</td>\n",
       "      <td>0.042734</td>\n",
       "      <td>0.025102</td>\n",
       "      <td>20.658418</td>\n",
       "      <td>0.194617</td>\n",
       "      <td>1.786932</td>\n",
       "      <td>0.042734</td>\n",
       "      <td>0.025102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>537.374600</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>671.962735</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>837.602885</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>6728.970000</td>\n",
       "      <td>1117.000000</td>\n",
       "      <td>406.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>147.000000</td>\n",
       "      <td>373.000000</td>\n",
       "      <td>169.000000</td>\n",
       "      <td>1117.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>124.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1117.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>124.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         tx_amt_avg        tx_cnt    ecfg_count   flbmk_count  \\\n",
       "count  95214.000000  95214.000000  95214.000000  95214.000000   \n",
       "mean     732.571089     15.982807      4.067417      0.053280   \n",
       "std      338.143649     21.017744     10.538025      0.336961   \n",
       "min        0.000000      1.000000      0.000000      0.000000   \n",
       "25%      537.374600      4.000000      0.000000      0.000000   \n",
       "50%      671.962735      9.000000      1.000000      0.000000   \n",
       "75%      837.602885     20.000000      4.000000      0.000000   \n",
       "max     6728.970000   1117.000000    406.000000     17.000000   \n",
       "\n",
       "       flg_3dsmk_count   insfg_count   ovrlt_count       stscd_0  \\\n",
       "count     95214.000000  95214.000000  95214.000000  95214.000000   \n",
       "mean          0.675730      0.444388      0.212689     15.782816   \n",
       "std           2.417233      2.196183      2.001265     20.658418   \n",
       "min           0.000000      0.000000      0.000000      0.000000   \n",
       "25%           0.000000      0.000000      0.000000      4.000000   \n",
       "50%           0.000000      0.000000      0.000000      9.000000   \n",
       "75%           0.000000      0.000000      0.000000     20.000000   \n",
       "max         147.000000    373.000000    169.000000   1117.000000   \n",
       "\n",
       "            stscd_1       stscd_2       stscd_3       stscd_4       stscd_0  \\\n",
       "count  95214.000000  95214.000000  95214.000000  95214.000000  95214.000000   \n",
       "mean       0.004285      0.194362      0.001134      0.000210     15.782816   \n",
       "std        0.194617      1.786932      0.042734      0.025102     20.658418   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      4.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      9.000000   \n",
       "75%        0.000000      0.000000      0.000000      0.000000     20.000000   \n",
       "max       29.000000    124.000000      3.000000      6.000000   1117.000000   \n",
       "\n",
       "            stscd_1       stscd_2       stscd_3       stscd_4  \n",
       "count  95214.000000  95214.000000  95214.000000  95214.000000  \n",
       "mean       0.004285      0.194362      0.001134      0.000210  \n",
       "std        0.194617      1.786932      0.042734      0.025102  \n",
       "min        0.000000      0.000000      0.000000      0.000000  \n",
       "25%        0.000000      0.000000      0.000000      0.000000  \n",
       "50%        0.000000      0.000000      0.000000      0.000000  \n",
       "75%        0.000000      0.000000      0.000000      0.000000  \n",
       "max       29.000000    124.000000      3.000000      6.000000  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count stscd_type for each acct\n",
    "stscd_pvt = train_raw.pivot_table(index = ['bacno'], columns=['stscd'],values='conam',aggfunc='count')\n",
    "stscd_pvt.replace(np.NAN, 0,inplace = True)\n",
    "col_nm_stscd = ['stscd_'+str(i) for i in range(5) ]\n",
    "stscd_pvt.columns = col_nm_stscd\n",
    "\n",
    "by_txn = pd.concat([by_txn, stscd_pvt], axis=1)\n",
    "by_txn.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### clustering\n",
    "    try to cluster accts into groups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. k-means\n",
    "- result : 5 or 6 groups is good\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-means\n",
    "from sklearn import cluster\n",
    "inertia_record = []\n",
    "\n",
    "X = by_txn\n",
    "for n in range(1,15):\n",
    "    k_means = cluster.KMeans(n_clusters=n)\n",
    "    k_means.fit(X) \n",
    "    inertia_record.append(k_means.inertia_)\n",
    "\n",
    "plt.plot([i for i in range(1,15)],inertia_record)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. novelty/outlier detection model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- one-class SMV\n",
    "    \n",
    "    > Hmm..... <br/>\n",
    "    > not doing good\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select wanted fearture and paramater\n",
    "elements_col = np.setdiff1d(train_raw.columns.values, ['cano','bacno','fraud_ind','txkey'])\n",
    "label_col = 'fraud_ind'\n",
    "all_col = np.append(elements_col,label_col)\n",
    "sample_fraction = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import OneClassSVM\n",
    "sample_data = train_raw[all_col].sample((round(N/sample_fraction)))\n",
    "train_x = sample_data[elements_col]\n",
    "train_y = sample_data[label_col]\n",
    "train_x.replace(np.NAN, 0,inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rbf': (array([-1, -1, -1, ...,  1,  1,  1]), 14121, 1097)}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compare model\n",
    "kernel_options = ['rbf', 'sigmoid','poly']\n",
    "kernel_options = [kernel_options[0]]\n",
    "fun_compare = {}\n",
    "for ko in kernel_options:\n",
    "    clf = OneClassSVM(degree = 3, kernel=ko, gamma='auto', nu=20355/1501432).fit(train_x)\n",
    "    pred = clf.predict(train_x)\n",
    "    fun_compare[ko]=(pred, len(np.where(pred==1)[0]),len(np.where(pred==-1)[0]))\n",
    "fun_compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_evl(pred, label):\n",
    "    if len(pred)!=len(label):\n",
    "        raise Exception('length not equal, plz chk, pred:%s, label: %s'%(len(pred), len(label)))\n",
    "    evl = {}\n",
    "    if sorted(np.unique(pred)) == [-1,1]:\n",
    "        pred[pred==-1]=0\n",
    "    a = pd.concat([pd.Series(pred, name='pred'), label.reset_index()['fraud_ind']],axis=1)\n",
    "    #evl['ACC'] = sum(a['pred']==a['fraud_ind'])/len(pred) # accuracy\n",
    "    evl['TP'] = sum((a['pred']==1) & (a['fraud_ind'] ==0)) # inlier & non-fraud\n",
    "    evl['TN'] = sum((a['pred']==0) & (a['fraud_ind'] ==1)) # outlier & fraud\n",
    "    evl['FA'] = sum((a['pred']==1) & (a['fraud_ind'] ==1)) # \n",
    "    evl['MS'] = sum((a['pred']==0) & (a['fraud_ind'] ==0)) # \n",
    "    evl['ACC'] = (evl['TP']+evl['TN'])/len(pred)\n",
    "    return evl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rbf : {'TP': 13933, 'TN': 5, 'FA': 188, 'MS': 1092, 'ACC': 0.9158890787225654}\n"
     ]
    }
   ],
   "source": [
    "for f in kernel_options:\n",
    "    evl_f = model_evl(fun_compare[f][0], train_y)\n",
    "    print(f,':', evl_f)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- isolation forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.6s finished\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/scipy/stats/stats.py:1706: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  return np.add.reduce(sorted[indexer] * weights, axis=axis) / sumval\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'ACC': 0.9034695755026941, 'FA': 70, 'MS': 1399, 'TN': 123, 'TP': 13626}"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#try isolation forest\n",
    "from sklearn.ensemble import IsolationForest\n",
    "clf = IsolationForest(bootstrap=True,  max_samples=500, max_features=3, contamination=0.1, verbose=1, n_estimators=250)\n",
    "clf.fit(train_x)\n",
    "\n",
    "pred = clf.predict(train_x)\n",
    "pred\n",
    "\n",
    "model_evl(pred,train_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
