{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try PCA\n",
    "\n",
    "## some ideas:\n",
    "- create new cols store information by acct\n",
    "- clustering the acct by avg_txn_amt, avg_month_amt, types of spending type, acc_code.....\n",
    "\n",
    "#### even more ideas: \n",
    "- fit a dist model of txn time, txn number for every group --> give every txn a probability.\n",
    "- try use one-class SVM (for novelty detection) see <a href=\"http://papers.nips.cc/paper/1723-support-vector-method-for-novelty-detection.pdf\" > paper </a> for explain and exmple\n",
    "\n",
    "### by acct attribute\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# by txn\n",
    "def count_unique(df):\n",
    "    unique_dict = {}\n",
    "    for i in df.columns:\n",
    "        uni_val = df[i].unique()\n",
    "        unique_dict[i]=(len(uni_val), uni_val)\n",
    "    return unique_dict\n",
    "unique_dict = count_unique(train_raw)\n",
    "\n",
    "bool_col=[]\n",
    "for i in unique_dict:\n",
    "    if unique_dict[i][0]<=3:\n",
    "        bool_col.append(i)\n",
    "\n",
    "bool_col.remove('fraud_ind')\n",
    "bool_agg = {i:'sum' for i in bool_col}\n",
    "\n",
    "col_nm_txn = ['tx_amt_avg', 'tx_cnt']\n",
    "by_txn = train_raw.groupby('bacno').agg({'conam':['mean','count'], **bool_agg})\n",
    "by_txn.columns=col_nm_txn+[i+'_count' for i in bool_col]\n",
    "by_txn.replace(np.NAN, 0,inplace = True)\n",
    "\n",
    "# count stscd_type for each acct\n",
    "stscd_pvt = train_raw.pivot_table(index = ['bacno'], columns=['stscd'],values='conam',aggfunc='count')\n",
    "stscd_pvt.replace(np.NAN, 0,inplace = True)\n",
    "col_nm_stscd = ['stscd_'+str(i) for i in range(5) ]\n",
    "stscd_pvt.columns = col_nm_stscd\n",
    "\n",
    "by_txn = pd.concat([by_txn, stscd_pvt], axis=1)\n",
    "\n",
    "### clustering\n",
    "\n",
    "by_txn.describe()\n",
    "\n",
    "# K-means\n",
    "from sklearn import cluster\n",
    "inertia_record = []\n",
    "\n",
    "X = by_txn\n",
    "for n in range(1,15):\n",
    "    k_means = cluster.KMeans(n_clusters=n)\n",
    "    k_means.fit(X) \n",
    "    inertia_record.append(k_means.inertia_)\n",
    "\n",
    "plt.plot([i for i in range(1,15)],inertia_record)\n",
    "# 5 or 6 group is good\n",
    "\n",
    "### novelty/outlier detection model\n",
    "\n",
    "#### try one-class SVM\n",
    "- Hmm.....\n",
    "- not doing good\n",
    "\n",
    "elements_col = np.setdiff1d(train_raw.columns.values, ['cano','bacno','fraud_ind','txkey'])\n",
    "label_col = 'fraud_ind'\n",
    "all_col = np.append(elements_col,label_col)\n",
    "sample_fraction = 100\n",
    "\n",
    "from sklearn.svm import OneClassSVM\n",
    "sample_data = train_raw[all_col].sample((round(N/sample_fraction)))\n",
    "train_x = sample_data[elements_col]\n",
    "train_y = sample_data[label_col]\n",
    "train_x.replace(np.NAN, 0,inplace = True)\n",
    "\n",
    "kernel_options = ['rbf', 'sigmoid','poly']\n",
    "kernel_options = [kernel_options[0]]\n",
    "fun_compare = {}\n",
    "for ko in kernel_options:\n",
    "    \n",
    "    clf = OneClassSVM(degree = 3, kernel=ko, gamma='auto', nu=20355/1501432).fit(train_x)\n",
    "    pred = clf.predict(train_x)\n",
    "    fun_compare[ko]=(pred, len(np.where(pred==1)[0]),len(np.where(pred==-1)[0]))\n",
    "fun_compare\n",
    "\n",
    "print(pred.shape,sum(train_y))\n",
    "\n",
    "a = pd.concat([pd.Series(fun_compare['rbf'][0], name='poly_pred'), train_y.reset_index()['fraud_ind']], axis=1)\n",
    "sum((a['poly_pred']==-1) & (a['fraud_ind']==1))\n",
    "#sum((a['poly_pred']==1) & (a['fraud_ind']==0))\n",
    "\n",
    "#try isolation forest\n",
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "clf = IsolationForest(bootstrap=True,  max_samples=500, max_features=3, contamination=0.1, verbose=1, n_estimators=250)\n",
    "clf.fit(train_x)\n",
    "\n",
    "pred = clf.predict(train_x)\n",
    "pred\n",
    "a = pd.concat([pd.Series(pred, name='forest'), train_y.reset_index()['fraud_ind']], axis=1)\n",
    "\n",
    "# correct predict fraud\n",
    "sum((a['forest']==-1) & (a['fraud_ind']==1))\n",
    "\n",
    "\n",
    "# correct predict non-fraud\n",
    "sum((a['forest']==1) & (a['fraud_ind']==0))\n",
    "\n",
    "# false predict fraud\n",
    "sum((a['forest']==-1) & (a['fraud_ind']==0))\n",
    "\n",
    "# false predict non-fraud\n",
    "sum((a['forest']==1) & (a['fraud_ind']==1))\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
